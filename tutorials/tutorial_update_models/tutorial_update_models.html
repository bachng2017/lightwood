

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Introduction &mdash; lightwood 22.9.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                22.9.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Tutorials</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">API</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../encoder.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Encoders</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mixer.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Mixers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Ensemble</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analysis.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Analysis</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../helpers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Helpers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lightwood_philosophy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Lightwood</span> <span class="pre">Philosophy</span></code></a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">lightwood</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Introduction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/tutorials/tutorial_update_models/tutorial_update_models.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Introduction">
<h1>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we will go through an example to update a preexisting model. This might be useful when you come across additional data that you would want to consider, without having to train a model from scratch.</p>
<p>The main abstraction that Lightwood offers for this is the <code class="docutils literal notranslate"><span class="pre">BaseMixer.partial_fit()</span></code> method. To call it, you need to pass new training data and a held-out dev subset for internal mixer usage (e.g. early stopping). If you are using an aggregate ensemble, it’s likely you will want to do this for every single mixer. The convienient <code class="docutils literal notranslate"><span class="pre">PredictorInterface.adjust()</span></code> does this automatically for you.</p>
</div>
<div class="section" id="Initial-model-training">
<h1>Initial model training<a class="headerlink" href="#Initial-model-training" title="Permalink to this headline">¶</a></h1>
<p>First, let’s train a Lightwood predictor for the <code class="docutils literal notranslate"><span class="pre">concrete</span> <span class="pre">strength</span></code> dataset:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightwood.api.high_level</span> <span class="kn">import</span> <span class="n">ProblemDefinition</span><span class="p">,</span> <span class="n">json_ai_from_problem</span><span class="p">,</span> <span class="n">predictor_from_json_ai</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2626:No torchvision detected, image helpers not supported.</span>
<span class="ansi-green-fg">INFO:lightwood-2626:No torchvision/pillow detected, image encoder not supported</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/mindsdb/lightwood/staging/tests/data/concrete_strength.csv&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))]</span>
<span class="n">update_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))]</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train dataframe shape: </span><span class="si">{</span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Update dataframe shape: </span><span class="si">{</span><span class="n">update_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test dataframe shape: </span><span class="si">{</span><span class="n">test_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train dataframe shape: (103, 10)
Update dataframe shape: (721, 10)
Test dataframe shape: (206, 10)
</pre></div></div>
</div>
<p>Note that we have three different data splits.</p>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">training</span></code> split for the initial model training. As you can see, it’s only a 20% of the total data we have. The <code class="docutils literal notranslate"><span class="pre">update</span></code> split will be used as training data to adjust/update our model. Finally, the held out <code class="docutils literal notranslate"><span class="pre">test</span></code> set will give us a rough idea of the impact our updating procedure has on the model’s predictive capabilities.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define predictive task and predictor</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;concrete_strength&#39;</span>
<span class="n">pdef</span> <span class="o">=</span> <span class="n">ProblemDefinition</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span> <span class="s1">&#39;time_aim&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">})</span>
<span class="n">jai</span> <span class="o">=</span> <span class="n">json_ai_from_problem</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">pdef</span><span class="p">)</span>

<span class="c1"># We will keep the architecture simple: a single neural mixer, and a `BestOf` ensemble:</span>
<span class="n">jai</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="s2">&quot;BestOf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="s2">&quot;$pred_args&quot;</span><span class="p">,</span>
        <span class="s2">&quot;accuracy_functions&quot;</span><span class="p">:</span> <span class="s2">&quot;$accuracy_functions&quot;</span><span class="p">,</span>
        <span class="s2">&quot;submodels&quot;</span><span class="p">:</span> <span class="p">[{</span>
            <span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="s2">&quot;Neural&quot;</span><span class="p">,</span>
            <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;fit_on_dev&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;stop_after&quot;</span><span class="p">:</span> <span class="s2">&quot;$problem_definition.seconds_per_mixer&quot;</span><span class="p">,</span>
                <span class="s2">&quot;search_hyperparameters&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">}]</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Build and train the predictor</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">predictor_from_json_ai</span><span class="p">(</span><span class="n">jai</span><span class="p">)</span>
<span class="n">predictor</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2626:Analyzing a sample of 979</span>
<span class="ansi-green-fg">INFO:lightwood-2626:from a total population of 1030, this is equivalent to 95.0% of your data.</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: id</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column id has data type integer</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: cement</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column cement has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: slag</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column slag has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: flyAsh</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column flyAsh has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: water</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column water has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: superPlasticizer</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column superPlasticizer has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: coarseAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column coarseAggregate has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: fineAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column fineAggregate has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: age</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column age has data type integer</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Infering type for: concrete_strength</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Column concrete_strength has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Finished statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Unable to import black formatter, predictor code might be a bit ugly.</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 1/8] - Statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Finished statistical analysis</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `analyze_data` runtime: 0.03 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 2/8] - Data preprocessing</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `preprocess` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 3/8] - Data splitting</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Splitting the data into train/test</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `split` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 4/8] - Preparing encoders</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: id</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: cement</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: slag</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: flyAsh</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: water</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: superPlasticizer</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: coarseAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: fineAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Done running for: age</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `prepare` runtime: 0.1 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 5/8] - Feature generation</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `featurize` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 6/8] - Mixer training</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Training the mixers</span>
torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
This overload of addcmul_ is deprecated:
        addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
        addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
<span class="ansi-green-fg">INFO:lightwood-2626:Loss of 7.153866291046143 with learning rate 0.0001</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss of 6.8837056159973145 with learning rate 0.00014</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss of 7.064479351043701 with learning rate 0.00019599999999999997</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Found learning rate of: 0.00014</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 1: 3.162095546722412</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 2: 3.4808480739593506</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 3: 3.4468672275543213</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 4: 3.4402384757995605</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 5: 3.3827364444732666</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 6: 3.3782267570495605</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 7: 3.304530143737793</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 8: 3.300995111465454</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 9: 3.214940071105957</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 10: 3.2120182514190674</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 11: 3.1162424087524414</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 12: 3.1137688159942627</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 13: 3.01035737991333</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 14: 3.0082414150238037</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 15: 2.8988308906555176</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 16: 2.897016763687134</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 17: 2.783118724822998</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 18: 2.7815678119659424</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 19: 2.6644930839538574</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 20: 2.6631782054901123</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 21: 2.5441019535064697</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 22: 2.5429975986480713</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 23: 2.422982692718506</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 24: 2.4220690727233887</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 25: 2.302001476287842</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 26: 2.301260471343994</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 27: 2.1820054054260254</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 28: 2.1814208030700684</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 29: 2.063715696334839</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 30: 2.0632710456848145</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 31: 1.9477651119232178</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 32: 1.9474451541900635</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 33: 1.8346989154815674</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 34: 1.8344911336898804</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 35: 1.724977970123291</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 36: 1.7248685359954834</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 37: 1.618973970413208</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 38: 1.6189501285552979</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 39: 1.5169769525527954</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 40: 1.5170263051986694</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 41: 1.4192277193069458</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 42: 1.419340968132019</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 43: 1.325916051864624</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 44: 1.3260842561721802</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 45: 1.2371675968170166</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 46: 1.2373806238174438</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 47: 1.1530762910842896</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 48: 1.1533257961273193</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 49: 1.073638677597046</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 50: 1.0739187002182007</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 51: 0.9987974166870117</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 52: 0.999101459980011</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 53: 0.928507924079895</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 54: 0.928829550743103</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 55: 0.8626793622970581</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 56: 0.8630120754241943</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 57: 0.8011684417724609</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 58: 0.801507294178009</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 59: 0.7438275218009949</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 60: 0.7441690564155579</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 61: 0.6904723644256592</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 62: 0.6908120512962341</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 63: 0.6409392952919006</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 64: 0.6412740349769592</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 65: 0.5950359106063843</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 66: 0.5953627228736877</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 67: 0.5525646209716797</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 68: 0.5528810024261475</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 69: 0.513323187828064</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 70: 0.5136263966560364</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 71: 0.4771132171154022</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 72: 0.4774025082588196</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 73: 0.44372856616973877</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 74: 0.44400283694267273</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 75: 0.41296884417533875</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 76: 0.4132263958454132</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 77: 0.3846345543861389</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 78: 0.38487595319747925</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 79: 0.358543336391449</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 80: 0.3587690591812134</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 81: 0.33454322814941406</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 82: 0.3347531259059906</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 83: 0.31246522068977356</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 84: 0.3126596212387085</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 85: 0.2921428084373474</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 86: 0.29232269525527954</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 87: 0.27343931794166565</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 88: 0.27360522747039795</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 89: 0.2562256157398224</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 90: 0.2563779950141907</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 91: 0.24037514626979828</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 92: 0.24051493406295776</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 93: 0.22578652203083038</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 94: 0.22591444849967957</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 95: 0.21234583854675293</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 96: 0.2124629020690918</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 97: 0.19996081292629242</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 98: 0.2000676691532135</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 99: 0.18854695558547974</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 100: 0.18864423036575317</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 101: 0.17803452908992767</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 102: 0.17812293767929077</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 103: 0.16833838820457458</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 104: 0.16841872036457062</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 105: 0.15939119458198547</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 106: 0.15946407616138458</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 107: 0.1511337161064148</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 108: 0.151199609041214</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 109: 0.1435091346502304</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 110: 0.14356893301010132</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 111: 0.13646595180034637</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 112: 0.1365201324224472</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 113: 0.12995712459087372</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 114: 0.13000629842281342</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 115: 0.12393999099731445</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 116: 0.12398432940244675</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 117: 0.11837441474199295</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 118: 0.11841466277837753</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 119: 0.11322391778230667</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 120: 0.11326029896736145</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 121: 0.10845529288053513</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 122: 0.10848837345838547</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 123: 0.10403768718242645</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 124: 0.10406771302223206</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 125: 0.0999443382024765</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 126: 0.09997159987688065</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 127: 0.0961480438709259</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 128: 0.096172995865345</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 129: 0.0926254466176033</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 130: 0.09264825284481049</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 131: 0.08935500681400299</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 132: 0.08937594294548035</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 133: 0.08631822466850281</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 134: 0.08633731305599213</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 135: 0.08349747955799103</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 136: 0.08351494371891022</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 137: 0.08087345957756042</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 138: 0.0808895006775856</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 139: 0.07843017578125</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 140: 0.0784449502825737</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 141: 0.07615318894386292</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 142: 0.0761668011546135</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 143: 0.0740291029214859</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 144: 0.07404157519340515</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 145: 0.07204649597406387</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 146: 0.07205799967050552</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 147: 0.07019531726837158</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 148: 0.07020591199398041</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 149: 0.06846503913402557</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 150: 0.06847492605447769</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 151: 0.06684551388025284</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 152: 0.0668545812368393</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 153: 0.06532759964466095</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 154: 0.06533605605363846</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 155: 0.06390313804149628</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 156: 0.06391094624996185</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 157: 0.0625658631324768</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 158: 0.06257309764623642</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 159: 0.061308957636356354</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 160: 0.0613156333565712</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 161: 0.06012523174285889</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 162: 0.06013139709830284</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 163: 0.05900917947292328</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 164: 0.05901492387056351</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 165: 0.05795574560761452</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 166: 0.05796102061867714</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 167: 0.056960176676511765</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 168: 0.056965067982673645</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 169: 0.056018222123384476</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 170: 0.05602269247174263</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 171: 0.05512585490942001</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 172: 0.055129941552877426</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 173: 0.054279521107673645</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 174: 0.054283302277326584</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 175: 0.053475916385650635</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 176: 0.05347947031259537</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 177: 0.05271228402853012</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 178: 0.05271557718515396</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 179: 0.05198604613542557</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 180: 0.05198908597230911</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 181: 0.05129483714699745</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 182: 0.05129767954349518</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 183: 0.05063660815358162</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 184: 0.05063919350504875</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 185: 0.05000946670770645</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 186: 0.050011951476335526</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 187: 0.049411747604608536</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 188: 0.04941414296627045</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 189: 0.0488419346511364</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 190: 0.04884418100118637</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 191: 0.04829869791865349</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 192: 0.04830075800418854</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 193: 0.04778038710355759</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 194: 0.04778226837515831</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 195: 0.04728569835424423</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 196: 0.0472874790430069</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 197: 0.046813998371362686</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 198: 0.046815671026706696</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 199: 0.046364251524209976</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 200: 0.04636577144265175</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 201: 0.04593560844659805</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 202: 0.04593712463974953</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 203: 0.04552730172872543</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 204: 0.04552868381142616</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 205: 0.0451384000480175</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 206: 0.04513971507549286</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 207: 0.04476826637983322</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 208: 0.044769540429115295</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 209: 0.04441629722714424</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 210: 0.04441754147410393</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 211: 0.04408185929059982</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 212: 0.04408304765820503</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 213: 0.043764468282461166</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 214: 0.04376551881432533</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 215: 0.04346352443099022</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 216: 0.04346450790762901</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 217: 0.04317828640341759</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 218: 0.04317918047308922</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 219: 0.04290812835097313</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 220: 0.04290897026658058</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 221: 0.042652640491724014</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 222: 0.042653489857912064</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 223: 0.042411498725414276</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 224: 0.04241231828927994</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 225: 0.04218415915966034</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 226: 0.04218496009707451</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 227: 0.041970327496528625</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 228: 0.04197108745574951</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 229: 0.04176963493227959</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 230: 0.0417703315615654</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 231: 0.04158157855272293</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 232: 0.04158216714859009</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 233: 0.04140692576766014</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 234: 0.04140745475888252</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 235: 0.04124433174729347</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 236: 0.0412447452545166</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 237: 0.04109252244234085</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 238: 0.04109293967485428</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 239: 0.04095109924674034</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 240: 0.04095141589641571</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 241: 0.04081958159804344</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 242: 0.040819842368364334</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 243: 0.040697574615478516</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 244: 0.040697868913412094</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 245: 0.04058486595749855</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 246: 0.0405849888920784</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 247: 0.040480710566043854</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 248: 0.040480826050043106</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 249: 0.040384870022535324</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 250: 0.0403849221765995</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 251: 0.04029689356684685</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 252: 0.04029691964387894</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 253: 0.04021612927317619</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 254: 0.04021613299846649</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 255: 0.04014238342642784</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 256: 0.04014241322875023</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 257: 0.040075670927762985</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 258: 0.04007556289434433</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 259: 0.04001564905047417</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 260: 0.040015529841184616</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 261: 0.039961811155080795</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 262: 0.03996160998940468</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 263: 0.039913590997457504</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 264: 0.03991340100765228</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 265: 0.039870548993349075</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 266: 0.039870209991931915</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 267: 0.039832066744565964</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 268: 0.03983166441321373</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 269: 0.039797887206077576</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 270: 0.03979744762182236</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 271: 0.039768002927303314</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 272: 0.03976759687066078</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 273: 0.03974192589521408</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 274: 0.03974149748682976</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 275: 0.03971996530890465</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 276: 0.03971938416361809</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 277: 0.03970235586166382</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 278: 0.039701830595731735</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 279: 0.03968769684433937</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 280: 0.03968712314963341</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 281: 0.03967548534274101</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 282: 0.03967494145035744</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 283: 0.039665646851062775</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 284: 0.03966507688164711</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 285: 0.03965789079666138</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 286: 0.03965733200311661</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 287: 0.03965215012431145</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 288: 0.03965151309967041</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 289: 0.03964811936020851</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 290: 0.03964753448963165</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 291: 0.0396457239985466</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 292: 0.039645079523324966</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 293: 0.03964453563094139</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 294: 0.03964388370513916</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 295: 0.03964449092745781</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `fit_mixer` runtime: 2.96 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Ensembling the mixer</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Mixer: Neural got accuracy: 0.281</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Picked best mixer: Neural</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `fit` runtime: 3.06 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 7/8] - Ensemble analysis</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Analyzing the ensemble of mixers</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block ICP is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block ConfStats is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block AccStats is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block PermutationFeatureImportance is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[PFI] Using a random sample (1000 rows out of 10).</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[PFI] Set to consider first 10 columns out of 9: [&#39;id&#39;, &#39;cement&#39;, &#39;slag&#39;, &#39;flyAsh&#39;, &#39;water&#39;, &#39;superPlasticizer&#39;, &#39;coarseAggregate&#39;, &#39;fineAggregate&#39;, &#39;age&#39;].</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `analyze_ensemble` runtime: 0.99 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Learn phase 8/8] - Adjustment on validation requested</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Updating the mixers</span>
torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 1: 0.09710239991545677</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 2: 0.06753953918814659</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 3: 0.08631765718261401</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 4: 0.06293793395161629</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 5: 0.07065049062172572</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 6: 0.053511256662507854</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 7: 0.06612508992354076</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `adjust` runtime: 0.04 seconds</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `learn` runtime: 4.25 seconds</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train and get predictions for the held out test set</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
<span class="n">predictions</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 1/4] - Data preprocessing</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `preprocess` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 2/4] - Feature generation</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `featurize` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 3/4] - Calling ensemble</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 4/4] - Analyzing output</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block ICP is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block ConfStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:ConfStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block AccStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:AccStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block PermutationFeatureImportance is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:PermutationFeatureImportance.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `predict` runtime: 1.85 seconds</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>original_index</th>
      <th>prediction</th>
      <th>confidence</th>
      <th>lower</th>
      <th>upper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>49.177926</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>99.741836</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>18.238433</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>68.802343</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>22.289931</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>72.853840</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>20.362166</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>70.926075</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>38.186172</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>88.750082</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>201</th>
      <td>201</td>
      <td>47.799281</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>98.363190</td>
    </tr>
    <tr>
      <th>202</th>
      <td>202</td>
      <td>41.190282</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>91.754192</td>
    </tr>
    <tr>
      <th>203</th>
      <td>203</td>
      <td>37.798300</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>88.362210</td>
    </tr>
    <tr>
      <th>204</th>
      <td>204</td>
      <td>29.786588</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>80.350498</td>
    </tr>
    <tr>
      <th>205</th>
      <td>205</td>
      <td>34.855963</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>85.419873</td>
    </tr>
  </tbody>
</table>
<p>206 rows × 5 columns</p>
</div></div>
</div>
<div class="section" id="Updating-the-predictor">
<h2>Updating the predictor<a class="headerlink" href="#Updating-the-predictor" title="Permalink to this headline">¶</a></h2>
<p>For this, we have two options:</p>
<div class="section" id="BaseMixer.partial_fit()">
<h3><code class="docutils literal notranslate"><span class="pre">BaseMixer.partial_fit()</span></code><a class="headerlink" href="#BaseMixer.partial_fit()" title="Permalink to this headline">¶</a></h3>
<p>Updates a single mixer. You need to pass the new data wrapped in <code class="docutils literal notranslate"><span class="pre">EncodedDs</span></code> objects.</p>
<p><strong>Arguments:</strong> * <code class="docutils literal notranslate"><span class="pre">train_data:</span> <span class="pre">EncodedDs</span></code> * <code class="docutils literal notranslate"><span class="pre">dev_data:</span> <span class="pre">EncodedDs</span></code></p>
<p>If the mixer does not need a <code class="docutils literal notranslate"><span class="pre">dev_data</span></code> partition, pass a dummy:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>dev_data = EncodedDs(predictor.encoders, pd.DataFrame(), predictor.target)
</pre></div>
</div>
</div>
<div class="section" id="PredictorInterface.adjust()">
<h3><code class="docutils literal notranslate"><span class="pre">PredictorInterface.adjust()</span></code><a class="headerlink" href="#PredictorInterface.adjust()" title="Permalink to this headline">¶</a></h3>
<p>Updates all mixers inside the predictor by calling their respective <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code> methods.</p>
<p><strong>Arguments:</strong> * <code class="docutils literal notranslate"><span class="pre">new_data:</span> <span class="pre">Union[EncodedDs,</span> <span class="pre">ConcatedEncodedDs,</span> <span class="pre">pd.DataFrame]</span></code> * <code class="docutils literal notranslate"><span class="pre">old_data:</span> <span class="pre">Optional[Union[EncodedDs,</span> <span class="pre">ConcatedEncodedDs,</span> <span class="pre">pd.DataFrame]]</span></code></p>
<p>Let’s <code class="docutils literal notranslate"><span class="pre">adjust</span></code> our predictor:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightwood.data</span> <span class="kn">import</span> <span class="n">EncodedDs</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">EncodedDs</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">encoders</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">update_ds</span> <span class="o">=</span> <span class="n">EncodedDs</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">encoders</span><span class="p">,</span> <span class="n">update_df</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="n">predictor</span><span class="o">.</span><span class="n">adjust</span><span class="p">(</span><span class="n">update_ds</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">)</span>  <span class="c1"># data to adjust and original data</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2626:Updating the mixers</span>
torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
<span class="ansi-green-fg">INFO:lightwood-2626:Loss @ epoch 1: 0.06666224698225658</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `adjust` runtime: 5.36 seconds</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
<span class="n">new_predictions</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 1/4] - Data preprocessing</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `preprocess` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 2/4] - Feature generation</span>
<span class="ansi-green-fg">INFO:lightwood-2626:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `featurize` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 3/4] - Calling ensemble</span>
<span class="ansi-green-fg">INFO:lightwood-2626:[Predict phase 4/4] - Analyzing output</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block ICP is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block ConfStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:ConfStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block AccStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:AccStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2626:The block PermutationFeatureImportance is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2626:PermutationFeatureImportance.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-white-fg">DEBUG:lightwood-2626: `predict` runtime: 1.83 seconds</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>original_index</th>
      <th>prediction</th>
      <th>confidence</th>
      <th>lower</th>
      <th>upper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>50.047745</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>100.611655</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>19.834124</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>70.398033</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>23.211976</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>73.775885</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>21.163995</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>71.727905</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>39.810138</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>90.374048</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>201</th>
      <td>201</td>
      <td>48.718162</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>99.282072</td>
    </tr>
    <tr>
      <th>202</th>
      <td>202</td>
      <td>41.109587</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>91.673497</td>
    </tr>
    <tr>
      <th>203</th>
      <td>203</td>
      <td>39.365741</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>89.929650</td>
    </tr>
    <tr>
      <th>204</th>
      <td>204</td>
      <td>30.945220</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>81.509130</td>
    </tr>
    <tr>
      <th>205</th>
      <td>205</td>
      <td>34.835177</td>
      <td>0.9991</td>
      <td>0.0</td>
      <td>85.399087</td>
    </tr>
  </tbody>
</table>
<p>206 rows × 5 columns</p>
</div></div>
</div>
<p>Nice! Our predictor was updated, and new predictions are looking good. Let’s compare the old and new accuracies:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">old_acc</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;concrete_strength&#39;</span><span class="p">],</span> <span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>
<span class="n">new_acc</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;concrete_strength&#39;</span><span class="p">],</span> <span class="n">new_predictions</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Old Accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">old_acc</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">New Accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">new_acc</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Old Accuracy: 0.442
New Accuracy: 0.473
</pre></div></div>
</div>
<p>After updating, we see an increase in the R2 score of predictions for the held out test set.</p>
</div>
</div>
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¶</a></h2>
<p>We have gone through a simple example of how Lightwood predictors can leverage newly acquired data to improve their predictions. The interface for doing so is fairly simple, requiring only some new data and a single call to update.</p>
<p>You can further customize the logic for updating your mixers by modifying the <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code> methods in them.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017-2022, MindsDB.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>